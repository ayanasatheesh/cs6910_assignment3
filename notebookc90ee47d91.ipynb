{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"gpuClass":"standard","accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"-8CnTZMcp_08","execution":{"iopub.status.busy":"2023-05-17T11:32:32.253239Z","iopub.execute_input":"2023-05-17T11:32:32.253714Z","iopub.status.idle":"2023-05-17T11:32:32.259426Z","shell.execute_reply.started":"2023-05-17T11:32:32.253681Z","shell.execute_reply":"2023-05-17T11:32:32.258493Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nwandb.login(key=\"99ed1e6d8f514ee3823dec88049f21d48e678419\")\nimport random\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport numpy as np","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXXBqk4cMz7p","outputId":"d6927c27-b84a-413c-fb67-e53aa4b5eb9f","execution":{"iopub.status.busy":"2023-05-17T11:32:32.273808Z","iopub.execute_input":"2023-05-17T11:32:32.274585Z","iopub.status.idle":"2023-05-17T11:32:43.375380Z","shell.execute_reply.started":"2023-05-17T11:32:32.274553Z","shell.execute_reply":"2023-05-17T11:32:43.374430Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.0)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.28.2)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.4)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.20.0)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"device","metadata":{"id":"YapAGpfhU_Ht","outputId":"d4c3af0c-2d1a-4e87-a42f-d7c11950998f","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-05-17T11:32:43.377835Z","iopub.execute_input":"2023-05-17T11:32:43.378195Z","iopub.status.idle":"2023-05-17T11:32:43.385808Z","shell.execute_reply.started":"2023-05-17T11:32:43.378153Z","shell.execute_reply":"2023-05-17T11:32:43.384886Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import csv\n\ndef read_dataset(file_path):\n    pairs = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        reader = csv.reader(f, delimiter=',')\n        for row in reader:\n            romanized_str = row[0].strip()\n            devanagari_str = row[1].strip()\n            romanized_str='['+romanized_str+']'\n            devanagari_str='['+devanagari_str+']'\n            pairs.append((romanized_str, devanagari_str))\n    return pairs","metadata":{"id":"845xcTcmRj83","execution":{"iopub.status.busy":"2023-05-17T11:32:43.387463Z","iopub.execute_input":"2023-05-17T11:32:43.388127Z","iopub.status.idle":"2023-05-17T11:32:43.397187Z","shell.execute_reply.started":"2023-05-17T11:32:43.388095Z","shell.execute_reply":"2023-05-17T11:32:43.396127Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTJSEOa7gTiT","outputId":"55122dc7-ddcc-4f67-e196-146fb6e72237"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path='/kaggle/input/aksrrrrrrrrrrrr/aksharantar_sampled/hin/hin_train.csv'\npairs=read_dataset(file_path)","metadata":{"id":"7g2NUIW9R0jW","execution":{"iopub.status.busy":"2023-05-17T11:32:43.400256Z","iopub.execute_input":"2023-05-17T11:32:43.401042Z","iopub.status.idle":"2023-05-17T11:32:43.506132Z","shell.execute_reply.started":"2023-05-17T11:32:43.400959Z","shell.execute_reply":"2023-05-17T11:32:43.505246Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"file_path='/kaggle/input/aksrrrrrrrrrrrr/aksharantar_sampled/hin/hin_valid.csv'\nvalid_pairs=read_dataset(file_path)\nfile_path='/kaggle/input/aksrrrrrrrrrrrr/aksharantar_sampled/hin/hin_test.csv'\ntest_pairs=read_dataset(file_path)","metadata":{"id":"EkMFBx0LG11m","execution":{"iopub.status.busy":"2023-05-17T11:32:43.507463Z","iopub.execute_input":"2023-05-17T11:32:43.507783Z","iopub.status.idle":"2023-05-17T11:32:43.528899Z","shell.execute_reply.started":"2023-05-17T11:32:43.507754Z","shell.execute_reply":"2023-05-17T11:32:43.528002Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"type(pairs[0][0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhPN4FIK52YP","outputId":"8ee9e710-f16a-4da5-e3d0-1f8cd04225f3","execution":{"iopub.status.busy":"2023-05-17T11:32:43.530487Z","iopub.execute_input":"2023-05-17T11:32:43.530818Z","iopub.status.idle":"2023-05-17T11:32:43.536881Z","shell.execute_reply.started":"2023-05-17T11:32:43.530789Z","shell.execute_reply":"2023-05-17T11:32:43.535949Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"str"},"metadata":{}}]},{"cell_type":"code","source":"SOS_token = '['\nEOS_token = ']'\n","metadata":{"id":"e9ebt6gIJBC8","execution":{"iopub.status.busy":"2023-05-17T11:32:43.538631Z","iopub.execute_input":"2023-05-17T11:32:43.539310Z","iopub.status.idle":"2023-05-17T11:32:43.546925Z","shell.execute_reply.started":"2023-05-17T11:32:43.539279Z","shell.execute_reply":"2023-05-17T11:32:43.545920Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"native_words=[]\ndevgiri_words=[]\n\ndef prepare_vocabulary(pairs):\n\n  native_character_vocabulary=set()\n  latin_character_vocabulary=set()\n  '''native_character_vocabulary.add('#')\n  native_character_vocabulary.add('[')\n  \n  latin_character_vocabulary.add('#')\n  latin_character_vocabulary.add('[')\n  native_character_vocabulary.add(']')\n  latin_character_vocabulary.add(']')'''\n  \n\n  native_enc_map={}\n  latin_enc_map={}\n  for (x,y) in pairs:\n    native_character_vocabulary=native_character_vocabulary.union(set(list(x)))\n    latin_character_vocabulary=latin_character_vocabulary.union(set(list(y)))\n    \n\n  #native_character_vocabulary=sorted(list(native_character_vocabulary))\n  #latin_character_vocabulary=sorted(list(latin_character_vocabulary))\n\n  \n\n  i=0\n  #native_char_map[SOS_token]=0\n  #native_char_map[EOS_token]=0\n  native_enc_map['#']=0\n  native_enc_map['[']=1\n  native_enc_map[']']=2\n  i=3\n  for ch in native_character_vocabulary:\n    if ch not in {'#','[',']'}:\n      native_enc_map[ch]=i\n      i+=1\n  \n  native_enc_map['?']=i\n  \n  #latin_char_map[SOS_token]=0\n  native_dec_map = {v: k for k, v in native_enc_map.items()}\n\n  i=0\n  latin_enc_map['#']=0\n  latin_enc_map['[']=1\n  latin_enc_map[']']=2\n  i=3\n  for ch in latin_character_vocabulary:\n    if ch not in {'#','[',']'}:\n      latin_enc_map[ch]=i\n      i+=1\n  latin_enc_map['?']=i\n  native_character_vocabulary.add('#')\n  native_character_vocabulary.add('[')\n  \n  latin_character_vocabulary.add('#')\n  latin_character_vocabulary.add('[')\n  native_character_vocabulary.add(']')\n  latin_character_vocabulary.add(']')  \n  #latin_char_map[EOS_token]=i\n  latin_dec_map = {v: k for k, v in latin_enc_map.items()}\n\n  return native_character_vocabulary,latin_character_vocabulary,native_enc_map,latin_enc_map,native_dec_map,latin_dec_map,pairs\n\n\nnative_character_vocabulary,latin_character_vocabulary,native_enc_map,latin_enc_map,native_dec_map,latin_dec_map,pairs=prepare_vocabulary(pairs)\n\n\n\n\n","metadata":{"id":"Oy2N5PtKIOaD","execution":{"iopub.status.busy":"2023-05-17T11:32:43.548459Z","iopub.execute_input":"2023-05-17T11:32:43.549111Z","iopub.status.idle":"2023-05-17T11:32:43.773612Z","shell.execute_reply.started":"2023-05-17T11:32:43.549081Z","shell.execute_reply":"2023-05-17T11:32:43.772798Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"native_enc_map","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OudXLqsLMz8J","outputId":"9a74a62a-d2d0-41e7-8625-ef8810b897b3","execution":{"iopub.status.busy":"2023-05-17T11:32:43.775102Z","iopub.execute_input":"2023-05-17T11:32:43.775430Z","iopub.status.idle":"2023-05-17T11:32:43.783151Z","shell.execute_reply.started":"2023-05-17T11:32:43.775400Z","shell.execute_reply":"2023-05-17T11:32:43.782257Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'#': 0,\n '[': 1,\n ']': 2,\n 'h': 3,\n 's': 4,\n 'u': 5,\n 'a': 6,\n 'l': 7,\n 'p': 8,\n 'v': 9,\n 'c': 10,\n 'f': 11,\n 'o': 12,\n 'b': 13,\n 'z': 14,\n 'w': 15,\n 'i': 16,\n 'd': 17,\n 'k': 18,\n 'q': 19,\n 'n': 20,\n 'm': 21,\n 'r': 22,\n 'g': 23,\n 'x': 24,\n 't': 25,\n 'e': 26,\n 'y': 27,\n 'j': 28,\n '?': 29}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"r5c9SPBz1h4n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x,y in pairs:\n  print(len(x),x)\n  break","metadata":{"id":"ya-qAlLtfhav","outputId":"fb701b28-7980-47c0-bf66-5352a73722f9","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-05-17T11:32:43.787150Z","iopub.execute_input":"2023-05-17T11:32:43.788070Z","iopub.status.idle":"2023-05-17T11:32:43.794538Z","shell.execute_reply.started":"2023-05-17T11:32:43.788038Z","shell.execute_reply":"2023-05-17T11:32:43.793551Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"13 [shastragaar]\n","output_type":"stream"}]},{"cell_type":"code","source":"max_encoder_seq_length = max([len(x) for x,y in pairs])\nmax_decoder_seq_length = max([len(y) for x,y in pairs])\n","metadata":{"id":"_CGbO20VctW8","execution":{"iopub.status.busy":"2023-05-17T11:32:43.795863Z","iopub.execute_input":"2023-05-17T11:32:43.796767Z","iopub.status.idle":"2023-05-17T11:32:43.820946Z","shell.execute_reply.started":"2023-05-17T11:32:43.796735Z","shell.execute_reply":"2023-05-17T11:32:43.819900Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(max_encoder_seq_length)\nprint(max_decoder_seq_length)","metadata":{"id":"he8UiH40c4fV","outputId":"81818a12-5404-4b9d-d46c-64e9e4f45f6e","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-05-17T11:32:43.822240Z","iopub.execute_input":"2023-05-17T11:32:43.822735Z","iopub.status.idle":"2023-05-17T11:32:43.828863Z","shell.execute_reply.started":"2023-05-17T11:32:43.822705Z","shell.execute_reply":"2023-05-17T11:32:43.827620Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"26\n22\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom torch.nn.utils.rnn import pad_sequence\ndef prepare_encoding(input,native_char_map,latin_char_map,batch_size):\n  #input_encoding = np.zeros((M, max_encoder_seq_length, num_input_tokens + 1), dtype=\"float\")\n  input_encoding=[torch.tensor([native_char_map[ch] for ch in train_pair[0]],device=device) for train_pair in input]\n  #input_encoding.append(EOS_token)\n  input_encoding = pad_sequence(input_encoding, batch_first=True,padding_value=0)\n  input_encoding=torch.tensor(input_encoding).to(device)\n  target_encoding=[torch.tensor([latin_char_map[ch] for ch in train_pair[1]],device=device)for train_pair in input]\n  #target_encoding.append(EOS_token)\n  target_encoding = pad_sequence(target_encoding, batch_first=True,padding_value=0)\n  target_encoding=torch.tensor(target_encoding).to(device)\n\n  return input_encoding.T,target_encoding.T\n\n\ninput_encoding,target_encoding=prepare_encoding(pairs[0:10],native_enc_map,latin_enc_map,10)","metadata":{"id":"y5fN09hdf7rS","outputId":"b3d51675-4f7d-4409-fb59-54cec78373a5","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-05-17T11:32:43.830509Z","iopub.execute_input":"2023-05-17T11:32:43.830884Z","iopub.status.idle":"2023-05-17T11:32:43.846157Z","shell.execute_reply.started":"2023-05-17T11:32:43.830854Z","shell.execute_reply":"2023-05-17T11:32:43.845102Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3310807116.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  input_encoding=torch.tensor(input_encoding).to(device)\n/tmp/ipykernel_31/3310807116.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  target_encoding=torch.tensor(target_encoding).to(device)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.core.displayhook import Float\nimport numpy as np\nfrom torch.nn.utils.rnn import pad_sequence\ndef prepare_encoding(input,native_char_map,latin_char_map,batch_size):\n  #input_encoding = np.zeros((M, max_encoder_seq_length, num_input_tokens + 1), dtype=\"float\")\n  input_encoding=[torch.tensor([native_char_map[ch] if ch in native_character_vocabulary else native_char_map['?'] for ch in train_pair[0]],device=device) for train_pair in input]\n  #input_encoding.append(EOS_token)\n  input_encoding = pad_sequence(input_encoding, batch_first=True,padding_value=0)\n  input_encoding=torch.tensor(input_encoding).to(device)\n  target_encoding=[torch.tensor([latin_char_map[ch] if ch in latin_character_vocabulary else latin_char_map['?'] for ch in train_pair[1]],device=device)for train_pair in input]\n  #target_encoding.append(EOS_token)\n  target_encoding = pad_sequence(target_encoding, batch_first=True,padding_value=0)\n  target_encoding=torch.tensor(target_encoding).to(device)\n\n  return input_encoding.T,target_encoding.T\n\ninput_encoding,target_encoding=prepare_encoding(pairs[0:10],native_enc_map,latin_enc_map,10)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7d5daba-7bce-488d-ea4d-9cfba75d6b16","id":"KsdJ7J6zSGBR","execution":{"iopub.status.busy":"2023-05-17T11:32:43.847471Z","iopub.execute_input":"2023-05-17T11:32:43.848358Z","iopub.status.idle":"2023-05-17T11:32:43.860808Z","shell.execute_reply.started":"2023-05-17T11:32:43.848327Z","shell.execute_reply":"2023-05-17T11:32:43.859697Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/11156412.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  input_encoding=torch.tensor(input_encoding).to(device)\n/tmp/ipykernel_31/11156412.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  target_encoding=torch.tensor(target_encoding).to(device)\n","output_type":"stream"}]},{"cell_type":"code","source":"input_encoding","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wfeOR1QsMz8n","outputId":"0a32fef4-8b7a-495d-b589-eef0fee756d7","execution":{"iopub.status.busy":"2023-05-17T11:32:43.862272Z","iopub.execute_input":"2023-05-17T11:32:43.862792Z","iopub.status.idle":"2023-05-17T11:32:43.881065Z","shell.execute_reply.started":"2023-05-17T11:32:43.862761Z","shell.execute_reply":"2023-05-17T11:32:43.880015Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n        [ 4, 13, 18, 27, 22,  9, 17,  4, 21,  4],\n        [ 3, 16, 16,  6,  6,  6, 26,  5, 12,  6],\n        [ 6, 20, 22, 23, 25, 23,  4, 23,  3, 22],\n        [ 4, 17,  6, 27,  6,  6,  3,  3, 16,  9],\n        [25,  3, 20, 12, 20, 20, 13,  6, 15,  6],\n        [22, 27, 18,  8, 16, 27,  3, 17,  6,  4],\n        [ 6,  6,  6,  6,  6,  6,  6,  8,  7,  6],\n        [23,  2, 20,  9,  2, 10, 22,  6,  2, 20],\n        [ 6,  0, 25, 26,  0,  3,  6, 20,  0, 23],\n        [ 6,  0,  2, 26,  0, 26, 21,  2,  0, 22],\n        [22,  0,  0, 25,  0,  2,  6,  0,  0,  6],\n        [ 2,  0,  0,  2,  0,  0, 17,  0,  0,  3],\n        [ 0,  0,  0,  0,  0,  0,  3,  0,  0,  2],\n        [ 0,  0,  0,  0,  0,  0, 27,  0,  0,  0],\n        [ 0,  0,  0,  0,  0,  0, 26,  0,  0,  0],\n        [ 0,  0,  0,  0,  0,  0,  2,  0,  0,  0]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"def accuracy(output,target,pair):\n  count=0\n  \n  bat=output.shape[1]\n  for i in range(output.shape[1]):\n    pred=output[:,i]\n    #print(pred)\n    tar_pair=pair[i][1]\n    tar=target[:,i]\n    \n    tar=tar.tolist()\n    pred=pred.tolist()\n    ind=tar.index(2)\n    \n    tar=tar[:ind]\n    pred=pred[:ind]\n    \n    ans=\"\"\n    for j in range(len(tar)):\n        ans+=latin_dec_map[pred[j]]\n    ans=ans[1:]\n    tar_pair=tar_pair[1:]\n    tar_pair=tar_pair[:-1]\n    #print(ans)\n    #print(tar_pair)\n    if(ans==tar_pair):\n      count+=1\n  #print(count)\n  return count/output.shape[1]\n\n","metadata":{"id":"q4YCUjAvRKNy","execution":{"iopub.status.busy":"2023-05-17T11:32:43.882726Z","iopub.execute_input":"2023-05-17T11:32:43.883117Z","iopub.status.idle":"2023-05-17T11:32:43.893348Z","shell.execute_reply.started":"2023-05-17T11:32:43.883086Z","shell.execute_reply":"2023-05-17T11:32:43.891026Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"valid_inp_encoding,valid_target_encoding=prepare_encoding(valid_pairs,native_enc_map,latin_enc_map,len(valid_pairs))\nprint(accuracy(valid_target_encoding,valid_target_encoding,valid_pairs))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzNHZs4i1sxk","outputId":"ec5a8d56-80f0-4f1e-9a67-b5c8732aa3d8","execution":{"iopub.status.busy":"2023-05-17T11:32:43.894512Z","iopub.execute_input":"2023-05-17T11:32:43.895640Z","iopub.status.idle":"2023-05-17T11:32:44.430877Z","shell.execute_reply.started":"2023-05-17T11:32:43.895614Z","shell.execute_reply":"2023-05-17T11:32:44.429961Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/11156412.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  input_encoding=torch.tensor(input_encoding).to(device)\n/tmp/ipykernel_31/11156412.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  target_encoding=torch.tensor(target_encoding).to(device)\n","output_type":"stream"},{"name":"stdout","text":"1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchtext\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, n_input,n_embedding, n_hidden, n_layers, cell_type,p,bidirectional):\n        super(EncoderRNN, self).__init__()\n        self.n_hidden = n_hidden\n        self.n_layers = n_layers\n        self.dropout=nn.Dropout(p)\n        self.cell_type=cell_type\n        self.directions=2 if bidirectional else 1\n        self.embedding_layer = nn.Embedding(n_input, n_embedding)\n        if cell_type == 'RNN':\n            self.rnn_cell = nn.RNN(n_embedding, n_hidden, n_layers,dropout=p,bidirectional=bidirectional)\n        elif cell_type == 'LSTM':\n            self.rnn_cell = nn.LSTM(n_embedding, n_hidden, n_layers,dropout=p,bidirectional=bidirectional)\n        elif cell_type == 'GRU':\n            self.rnn_cell = nn.GRU(n_embedding, n_hidden, n_layers,dropout=p,bidirectional=bidirectional)\n        #if(bidirectional):\n\n\n    def forward(self, input, hidden,cell=None):\n        #print(input.shape)\n        embedded = self.dropout(self.embedding_layer(input))\n        #print(embedded.shape)\n        output = embedded.unsqueeze(0)\n        #hidden.squeeze(0)\n        #print(hidden.shape)\n        #print(output.shape)\n        if(self.cell_type=='LSTM'):\n          \n            output,(hidden,cell)=self.rnn_cell(output,(hidden,cell))\n            return output,hidden,cell\n        else:\n          output, hidden = self.rnn_cell(output, hidden)\n          return output, hidden\n\n    def initHidden(self,batch_size):\n        return torch.zeros(self.n_layers*self.directions, batch_size, self.n_hidden, device=device)\n\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, n_input,n_embedding, n_hidden, n_output, n_layers, cell_type,p,bidirectional):\n        super(DecoderRNN, self).__init__()\n        self.n_hidden = n_hidden\n        self.n_layers = n_layers\n        self.cell_type=cell_type\n        self.dropout=nn.Dropout(p)\n\n        self.embedding_layer = nn.Embedding(n_input, n_embedding)\n        if cell_type == 'RNN':\n            self.rnn_layer = nn.RNN(n_embedding, n_hidden, n_layers,dropout=p,bidirectional=bidirectional)\n        elif cell_type == 'LSTM':\n            self.rnn_layer = nn.LSTM(n_embedding, n_hidden,n_layers,dropout=p,bidirectional=bidirectional)\n        elif cell_type == 'GRU':\n            self.rnn_layer = nn.GRU(n_embedding, n_hidden, n_layers,dropout=p,bidirectional=bidirectional)\n        #self.fc = nn.Linear(hidden_size, output_size)\n        if(bidirectional):\n            self.out = nn.Linear(2*n_hidden, n_output)\n        else:\n            self.out = nn.Linear(n_hidden, n_output)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden,cell=None):\n        output = self.dropout(self.embedding_layer(input))\n        output=output.unsqueeze(0)\n        output = F.relu(output)\n        #print(output.shape)\n        #print(hidden.shape)\n        #print(cell.shape)\n        if(self.cell_type=='LSTM'):\n          output,(hidden,cell)=self.rnn_layer(output,(hidden,cell))\n          \n          output=self.softmax(self.out(output[0]))\n          #print(output.shape,\"&&&&&&&\")\n          return output,hidden,cell\n        else:\n          output, hidden = self.rnn_layer(output, hidden)\n          output = self.softmax(self.out(output[0]))\n          return output, hidden\n\n    def initHidden(self,batch_size):\n        return torch.zeros(self.n_layers,batch_size,self.n_hidden, device=device)\n\n\nteacher_forcing_ratio = 1\n\ndef trainnet(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,validation=False):\n    \n    if(not(validation)):\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n    #temp_layer=nn.Linear(2*encoder.n_layers,2*decoder.n_layers,device=device)\n\n    input_length = input_tensor.shape[0]\n    target_length = target_tensor.shape[0]\n    batch_size=input_tensor.shape[1]\n    encoder_hidden = encoder.initHidden(batch_size)\n    encoder_cell=encoder.initHidden(batch_size)\n\n    encoder_outputs = torch.zeros(input_length,batch_size,encoder.n_hidden, device=device)\n    decoder_outputs=torch.zeros(target_length,batch_size,device=device)\n\n    loss = 0\n    if(encoder.cell_type=='LSTM'):\n      #encoder_output, encoder_hidden,encoder_cell=encoder(input_tensor[0],encoder_hidden)\n      #encoder_outputs[0]=encoder_output[0,0]\n      for ei in range(0,input_length):\n          encoder_output, encoder_hidden,encoder_cell = encoder(\n              input_tensor[ei], encoder_hidden,encoder_cell)\n          #print(encoder_cell.shape,\"****\")\n          #encoder_outputs[ei] = encoder_output[0, 0]\n\n    \n    else:\n      for ei in range(0,input_length):\n          encoder_output, encoder_hidden = encoder(\n              input_tensor[ei], encoder_hidden)\n    \n    #decoder_hidden = temp_layer(encoder_hidden.permute(1,2,0))\n    #decoder_hidden=decoder_hidden.permute(2,0,1).contiguous()\n    #print(encoder_hidden.shape)\n    decoder_input = target_tensor[0]\n    decoder_hidden=encoder_hidden\n    decoder_cell=encoder_cell\n\n    #decoder_cell=temp_layer(encoder_cell.permute(1,2,0))\n    #decoder_cell=decoder_cell.permute(2,0,1).contiguous()\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if(validation):\n        if encoder.cell_type=='LSTM':\n           for di in range(target_length):\n                  decoder_output, decoder_hidden,decoder_cell = decoder(\n                      decoder_input, decoder_hidden, decoder_cell)\n                  topv, topi = decoder_output.topk(1)\n                  #print(topi.shape,\"UUUUUUUUUUUU\")\n                  decoder_input = topi.squeeze().detach()\n                  decoder_outputs[di]=decoder_input\n           return decoder_outputs\n        else:\n           for di in range(target_length):\n                  decoder_output, decoder_hidden= decoder(\n                      decoder_input, decoder_hidden)\n                  topv, topi = decoder_output.topk(1)\n                  #print(topi.shape,\"UUUUUUUUUUUU\")\n                  decoder_input = topi.squeeze().detach()\n                  decoder_outputs[di]=decoder_input\n           return decoder_outputs \n\n    else:\n      if use_teacher_forcing:\n          # Teacher forcing: Feed the target as the next input\n          if encoder.cell_type=='LSTM':\n            for di in range(target_length):\n                #print(decoder_cell.shape)\n                decoder_output, decoder_hidden, decoder_cell = decoder(decoder_input, decoder_hidden, decoder_cell)\n                loss += criterion(decoder_output, target_tensor[di])\n                decoder_input = target_tensor[di] \n          else:\n             for di in range(target_length):\n                #print(decoder_cell.shape)\n                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n                loss += criterion(decoder_output, target_tensor[di])\n                decoder_input = target_tensor[di] \n\n      else:\n          # Without teacher forcing: use its own predictions as the next input\n        if encoder.cell_type=='LSTM':\n          for di in range(target_length):\n              decoder_output, decoder_hidden,decoder_cell = decoder(\n                  decoder_input, decoder_hidden, decoder_cell)\n              topv, topi = decoder_output.topk(1)\n              #print(topi.shape,\"UUUUUUUUUUUU\")\n              decoder_input = topi.squeeze().detach()  # detach from history as input\n        else:\n            for di in range(target_length):\n              decoder_output, decoder_hidden = decoder(\n                  decoder_input, decoder_hidden)\n              topv, topi = decoder_output.topk(1)\n              #print(topi.shape,\"UUUUUUUUUUUU\")\n              decoder_input = topi.squeeze().detach()  # detach from history as input\n\n        loss += criterion(decoder_output, target_tensor[di])\n              \n\n      loss.backward()\n\n      encoder_optimizer.step()\n      decoder_optimizer.step()\n\n      return loss.item() / target_length\n\ndef trainIters(encoder, decoder, epochs, batch_size, learning_rate):\n    \n   \n    print(f\"{'epoch': <5}{'training loss' : ^30}{'training accuracy ': <30}{'validation loss ': <30}\")\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    \n    criterion = nn.NLLLoss()\n    for epoch in range(epochs):\n      loss=0\n      count=0\n      sumloss=0\n      acc=0\n      tot_ans=[]\n      for i in range(0,len(pairs),batch_size):\n        input_encoding,target_encoding=prepare_encoding(pairs[i:i+batch_size],native_enc_map,latin_enc_map,batch_size)\n\n   \n        input_tensor = input_encoding\n        target_tensor = target_encoding\n\n        loss = trainnet(input_tensor, target_tensor, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n        sumloss+=loss\n        count+=1\n      \n\n      valid_inp_encoding,valid_target_encoding=prepare_encoding(valid_pairs,native_enc_map,latin_enc_map,len(valid_pairs))\n      valid_out=trainnet(valid_inp_encoding, valid_target_encoding, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion,True)\n      #valid_out,valid_target=prepare(valid_out,valid_target_encoding)\n      print(valid_out.shape,valid_target_encoding.shape)\n      valid_acc=accuracy(valid_out,valid_target_encoding,valid_pairs)\n      #print(valid_acc)\n      wandb.log({\"validation_accuracy\": valid_acc,\"training_loss\": sumloss/count,\"epoch\":epoch})\n      print(f\"{epoch : <5}{sumloss/count : ^30}{acc: <30}{valid_acc : <30}\")\n     \n\n''''hidden_size = 256\nnum_layers=2\nenc_dropout=0\ndec_dropout=0\nencoder_embedding_size=256\ndecoder_embedding_size=256\noutput_size=len(latin_character_vocabulary)\ninput_size_encoder=len(native_character_vocabulary)\ninput_size_decoder=len(latin_character_vocabulary)\n\nencoder1=EncoderRNN(input_size_encoder,encoder_embedding_size,hidden_size,2,'LSTM',enc_dropout,True).to(device)\ndecoder1=DecoderRNN(input_size_decoder, decoder_embedding_size, hidden_size, output_size, 2, 'LSTM', dec_dropout,True).to(device)'''''\n\n\n#trainIters(encoder1, decoder1, 7,16,0.001)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uudz5uvHW2d-","outputId":"f00b3136-34ac-4bfe-d4cc-bb59a6f6f162","execution":{"iopub.status.busy":"2023-05-17T11:42:37.151316Z","iopub.execute_input":"2023-05-17T11:42:37.151664Z","iopub.status.idle":"2023-05-17T11:42:37.203666Z","shell.execute_reply.started":"2023-05-17T11:42:37.151636Z","shell.execute_reply":"2023-05-17T11:42:37.202722Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"\"'hidden_size = 256\\nnum_layers=2\\nenc_dropout=0\\ndec_dropout=0\\nencoder_embedding_size=256\\ndecoder_embedding_size=256\\noutput_size=len(latin_character_vocabulary)\\ninput_size_encoder=len(native_character_vocabulary)\\ninput_size_decoder=len(latin_character_vocabulary)\\n\\nencoder1=EncoderRNN(input_size_encoder,encoder_embedding_size,hidden_size,2,'LSTM',enc_dropout,True).to(device)\\ndecoder1=DecoderRNN(input_size_decoder, decoder_embedding_size, hidden_size, output_size, 2, 'LSTM', dec_dropout,True).to(device)\""},"metadata":{}}]},{"cell_type":"code","source":"def network_train(epochs,n_layers,n_embedding,lr,batch_size,cell_type,bidirectional,enc_dropout,dec_dropout,n_hidden):\n    input_size_encoder=len(native_character_vocabulary)\n    input_size_decoder=len(latin_character_vocabulary)\n    \n    output_size=len(latin_character_vocabulary)\n    encoder_net=EncoderRNN(input_size_encoder,n_embedding,n_hidden,n_layers,cell_type,enc_dropout,bidirectional).to(device)\n    decoder_net=DecoderRNN(input_size_decoder, n_embedding, n_hidden, output_size, n_layers, cell_type, dec_dropout,bidirectional).to(device)\n\n\n    trainIters(encoder_net, decoder_net, epochs,batch_size,lr)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T11:54:27.431614Z","iopub.execute_input":"2023-05-17T11:54:27.432009Z","iopub.status.idle":"2023-05-17T11:54:27.439004Z","shell.execute_reply.started":"2023-05-17T11:54:27.431965Z","shell.execute_reply":"2023-05-17T11:54:27.437848Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',     \n    'metric': { 'name': 'validation_accuracy', 'goal': 'maximize'},\n    'parameters': {'epoch': {'values': [5, 10,15,20] } ,\n                   'n_embedding': { 'values': [16,32, 64, 256] },\n                  'n_layers':{ 'values':[1,2,3]  },\n                   'lr': {  'values': [1e-2,1e-3,1e-4]},\n                  'batch_size': {'values': [16, 32, 64] },\n                  'cell_type': {'values': ['RNN','LSTM','GRU'] },\n                    'bidirectional': {'values': [True,False] },\n                    'enc_dropout': {'values': [0,0.1,0.2,0.3] },\n                   'dec_dropout': {'values': [0,0.1,0.2,0.3] },\n                   'n_hidden': {'values': [16,32,64,256] },\n                 \n                   },\n    \n  }\n\ndef train():\n    run=wandb.init(project=\"assignment3\",entity=\"cs22m025\",reinit=True)\n    config = wandb.config\n    #took reference from wandb document\n    wandb.run.name=\"ep_{}_hl_{}_em_{}_lr_{}_bt_{}_cl_{}_bi_{}_edrp_{}_ddrp_{}_hl_{}\".format(config.epoch,config.n_layers,config.n_embedding,config.lr,config.batch_size,config.cell_type,config.bidirectional, config.enc_dropout,config.dec_dropout,config.n_hidden)\n    wandb.run.save\n    tot_ans=network_train(config.epoch,config.n_layers,config.n_embedding,config.lr,config.batch_size,config.cell_type,config.bidirectional, config.enc_dropout,config.dec_dropout,config.n_hidden)\n    run.finish()\n\n\nsweep_id = wandb.sweep(sweep=sweep_config, project=\"assignment3\")\n\nwandb.agent(sweep_id, function=train,count=30)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T11:38:41.762140Z","iopub.execute_input":"2023-05-17T11:38:41.762498Z","iopub.status.idle":"2023-05-17T11:42:09.015416Z","shell.execute_reply.started":"2023-05-17T11:38:41.762468Z","shell.execute_reply":"2023-05-17T11:42:09.014341Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Create sweep with ID: zv52kwhb\nSweep URL: https://wandb.ai/cs22m025/assignment3/sweeps/zv52kwhb\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: spaz303e with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_dropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_dropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embedding: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_hidden: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230517_113851-spaz303e</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m025/assignment3/runs/spaz303e' target=\"_blank\">exalted-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m025/assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m025/assignment3/sweeps/zv52kwhb' target=\"_blank\">https://wandb.ai/cs22m025/assignment3/sweeps/zv52kwhb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m025/assignment3' target=\"_blank\">https://wandb.ai/cs22m025/assignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m025/assignment3/sweeps/zv52kwhb' target=\"_blank\">https://wandb.ai/cs22m025/assignment3/sweeps/zv52kwhb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m025/assignment3/runs/spaz303e' target=\"_blank\">https://wandb.ai/cs22m025/assignment3/runs/spaz303e</a>"},"metadata":{}},{"name":"stdout","text":"epoch        training loss         training accuracy             validation loss               \n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/11156412.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  input_encoding=torch.tensor(input_encoding).to(device)\n/tmp/ipykernel_31/11156412.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  target_encoding=torch.tensor(target_encoding).to(device)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">exalted-sweep-1</strong> at: <a href='https://wandb.ai/cs22m025/assignment3/runs/spaz303e' target=\"_blank\">https://wandb.ai/cs22m025/assignment3/runs/spaz303e</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230517_113851-spaz303e/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run spaz303e errored: TypeError('train() takes 0 positional arguments but 8 were given')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run spaz303e errored: TypeError('train() takes 0 positional arguments but 8 were given')\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"QbZD_GHNxr8r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"_3tVU81lRaFU"},"execution_count":null,"outputs":[]}]}